{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction-to-Neural-Networks\" data-toc-modified-id=\"Introduction-to-Neural-Networks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction to Neural Networks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Non-Linear-Regions\" data-toc-modified-id=\"Non-Linear-Regions-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Non-Linear Regions</a></span></li><li><span><a href=\"#Error-Functions\" data-toc-modified-id=\"Error-Functions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Error Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Proerties-an-error-function-shoud-have\" data-toc-modified-id=\"Proerties-an-error-function-shoud-have-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Proerties an error function shoud have</a></span></li></ul></li><li><span><a href=\"#Move-from-Discrete-to-Continous-Predictions\" data-toc-modified-id=\"Move-from-Discrete-to-Continous-Predictions-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Move from Discrete to Continous Predictions</a></span></li><li><span><a href=\"#Multi-Class-Classification-and-Softmax\" data-toc-modified-id=\"Multi-Class-Classification-and-Softmax-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Multi-Class Classification and Softmax</a></span></li><li><span><a href=\"#One-Hot-Encoding\" data-toc-modified-id=\"One-Hot-Encoding-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>One-Hot Encoding</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Linear Regions\n",
    "\n",
    "**Example: Acceptance at a University**\n",
    "> Perceptron algorithm only build a linear boundary but in reality it is not always the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Functions\n",
    "\n",
    "**Pick a direction in which the error (height) descent the most.**\n",
    "\n",
    ">*Note that it is possible to stop at a local minimum*\n",
    "\n",
    "**Discrete vs Continous Error functions?**\n",
    "> Continous Error Function!!\n",
    "\n",
    ">*Discrete error function* may confuse the computer by giving the same error score for all directions.\n",
    "\n",
    "### Proerties an error function shoud have \n",
    "\n",
    "1. Continous\n",
    "2. Give penalty on the misclassified points\n",
    "3. Error decreases as the misclassified points are classified correctly\n",
    "4. Differentiable for gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move from Discrete to Continous Predictions\n",
    "\n",
    "*Yes/No* prediction to probability\n",
    "\n",
    "Map the **step function** (discrete) to **Sigmoid function** (continous)\n",
    "\n",
    "**Sigmoid function**\n",
    "\n",
    "- For large positive numbers, it gives value close to 1.\n",
    "\n",
    "- For large negative numbers, it gives value close to 0.\n",
    "\n",
    "- For number close to 0, it gives value close to 0.5.\n",
    "\n",
    "$$\n",
    "\\sigma(Wx+b) = \\frac{1}{1+e^{-Wx+b}},\n",
    "$$\n",
    "where \n",
    "$Wx_b$ is the linear boundary defined in perceptron algorithm.\n",
    "\n",
    "Thus, in the current perceptron algorithm, the activation function changes from step function to sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Class Classification and Softmax\n",
    "\n",
    "The **Softmax** function is the equivalent of the sigmoid activation funciton when the problem has 3 or more classes.\n",
    "\n",
    "**Properties of activation function for multi-class classification**\n",
    "- Add to 1;\n",
    "\n",
    "- positive scores;\n",
    "\n",
    "- monotonicity consistent with the linear scores\n",
    "\n",
    "> - **normalize by sum of the scores?**\n",
    "Issues: negative numbers? what if the sum is 0?\n",
    "  \n",
    "> - **return every score to a positive number and then normalize them?**\n",
    "exponential function and do normalization;\n",
    "Also exponetial function is increasing function as score increases\n",
    "\n",
    "$$\n",
    "P(class i) = \\frac{e^{Z_i}}{e^{Z_1} + e^{Z_2} + \\cdots + e^{Z_n}}\n",
    "$$\n",
    "\n",
    "Actually this is the same as sigmoid function when $n = 2$.\n",
    ">Proof:\n",
    "> Sigmoid function gives : \n",
    "$$\n",
    "y = Wx + b; p_1 = \\frac{1}{1 + e^{-y}}, p_0 = \\frac{1}{1+e^{y}}\n",
    "$$\n",
    "\n",
    "> Softmax function gives:\n",
    "$$\n",
    "p_1 = \\frac{1}{1 + e^{z1-z2}}, p_0 = \\frac{1}{1+ e^{z_2-z1}}\n",
    "$$\n",
    "Thus, let $z_2 - z_1= Wx +b$ then two functions are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding\n",
    "\n",
    "Given data of animals: duck, dog, cat.\n",
    "If we encoding by giving values 0, 1 and 2 for these animals, it introduces the dependency between animal types, which does not exist in our data.\n",
    "\n",
    "One-Hot Encoding will help with this situation.\n",
    "\n",
    "|Animal|Duck?|Dog?|Cat?|\n",
    "|:-|:-|:-|:-|\n",
    "|Duck| 1 | 0 | 0|\n",
    "|Dog | 0| 1| 0|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "25px",
    "width": "164px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
